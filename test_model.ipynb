{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "mlflow.set_experiment(\"Housing Prices Prediction\")\n",
    "\n",
    "# Load the Housing.csv dataset\n",
    "import dabl\n",
    "data_raw = pd.read_csv('data/Housing.csv')\n",
    "target = data_raw['price']\n",
    "data = data_raw.drop(['price'], axis=1)\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing 1 - OHE, keep all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data using dabl\n",
    "#cleaned_data = dabl.clean(data)\n",
    "#cleaned_data_encoded = pd.get_dummies(cleaned_data)\n",
    "\n",
    "# One-hot encode the categorical features\n",
    "cleaned_data_encoded = pd.get_dummies(data)\n",
    "cleaned_data_encoded.head()\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_data_encoded, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing 2 - check for multicolinearity, remove features with high values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            feature       VIF\n",
      "0                              area  1.325250\n",
      "1                          bedrooms  1.369477\n",
      "2                         bathrooms  1.286621\n",
      "3                           stories  1.478055\n",
      "4                           parking  1.212837\n",
      "5                       mainroad_no       inf\n",
      "6                      mainroad_yes       inf\n",
      "7                      guestroom_no       inf\n",
      "8                     guestroom_yes       inf\n",
      "9                       basement_no       inf\n",
      "10                     basement_yes       inf\n",
      "11               hotwaterheating_no       inf\n",
      "12              hotwaterheating_yes       inf\n",
      "13               airconditioning_no       inf\n",
      "14              airconditioning_yes       inf\n",
      "15                      prefarea_no       inf\n",
      "16                     prefarea_yes       inf\n",
      "17       furnishingstatus_furnished       inf\n",
      "18  furnishingstatus_semi-furnished       inf\n",
      "19     furnishingstatus_unfurnished       inf\n",
      "Selected Features:  Index(['area', 'bedrooms', 'bathrooms', 'stories', 'parking'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angus/Documents/GitHub/MLFlow/OAI-lab1/myenv/lib/python3.9/site-packages/statsmodels/stats/outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = cleaned_data_encoded.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(cleaned_data_encoded.values, i) for i in range(cleaned_data_encoded.shape[1])]\n",
    "\n",
    "# Display VIF\n",
    "print(vif_data)\n",
    "\n",
    "\n",
    "# Remove features with high VIF > 10\n",
    "high_vif_features = vif_data[vif_data[\"VIF\"] > 10]\n",
    "cleaned_data_encoded_selected = cleaned_data_encoded.drop(columns=high_vif_features[\"feature\"])\n",
    "print(\"Selected Features: \", cleaned_data_encoded_selected.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following lines to run processing 2\n",
    "\n",
    "#adjust the size of the target based on the index of the cleaned_data_encoded_selected\n",
    "#target2 = target[:len(cleaned_data_encoded_selected)]\n",
    "\n",
    "# train test split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(cleaned_data_encoded_selected, target2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Root Mean Squared Error for the linear regression model: 1324506.960091438\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Compute the Root Mean Squared Error\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, lr_pred))\n",
    "\n",
    "print(\"The Root Mean Squared Error for the linear regression model:\", rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angus/Documents/GitHub/MLFlow/OAI-lab1/myenv/lib/python3.9/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Linear Regression Model' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'Linear Regression Model'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Implement MLflow\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(lr_model.get_params())\n",
    "\n",
    "    # Log the RMSE metric\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Set a tag for tracking information\n",
    "    mlflow.set_tag(\"Training Info\", \"Dataset 2\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, lr_model.predict(X_train))\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=lr_model,\n",
    "        artifact_path=\"Linear_Regression_Model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train.head(),\n",
    "        registered_model_name=\"Linear Regression Model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Dabl Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DummyRegressor()\n",
      "r2: -0.018 neg_mean_squared_error: -3105569656113.664\n",
      "=== new best DummyRegressor() (using r2):\n",
      "r2: -0.018 neg_mean_squared_error: -3105569656113.664\n",
      "\n",
      "Running DecisionTreeRegressor(max_depth=1)\n",
      "r2: 0.311 neg_mean_squared_error: -2085951184459.935\n",
      "=== new best DecisionTreeRegressor(max_depth=1) (using r2):\n",
      "r2: 0.311 neg_mean_squared_error: -2085951184459.935\n",
      "\n",
      "Running DecisionTreeRegressor(max_leaf_nodes=8)\n",
      "r2: 0.540 neg_mean_squared_error: -1387749905514.373\n",
      "=== new best DecisionTreeRegressor(max_leaf_nodes=8) (using r2):\n",
      "r2: 0.540 neg_mean_squared_error: -1387749905514.373\n",
      "\n",
      "Running DecisionTreeRegressor(max_leaf_nodes=16)\n",
      "r2: 0.531 neg_mean_squared_error: -1415293931339.369\n",
      "Running DecisionTreeRegressor(max_leaf_nodes=32)\n",
      "r2: 0.458 neg_mean_squared_error: -1606663096588.816\n",
      "Running DecisionTreeRegressor(max_depth=5)\n",
      "r2: 0.524 neg_mean_squared_error: -1439531650928.209\n",
      "Running Ridge(alpha=10)\n",
      "r2: 0.518 neg_mean_squared_error: -1476361045154.512\n",
      "Running Lasso(alpha=10)\n",
      "r2: 0.509 neg_mean_squared_error: -1496097755836.804\n",
      "\n",
      "Best model:\n",
      "DecisionTreeRegressor(max_leaf_nodes=8)\n",
      "Best Scores:\n",
      "r2: 0.540 neg_mean_squared_error: -1387749905514.373\n",
      "The Root Mean Squared Error for the random forest regression model with the best parameters: 1805139.1531179908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angus/Documents/GitHub/MLFlow/OAI-lab1/myenv/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:241: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/angus/Documents/GitHub/MLFlow/OAI-lab1/myenv/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e+11, tolerance: 1.112e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/angus/Documents/GitHub/MLFlow/OAI-lab1/myenv/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.738e+11, tolerance: 1.131e+11\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Fit a simple regressor\n",
    "simple_regressor = dabl.SimpleRegressor().fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable\n",
    "pred = simple_regressor.predict(X_test)\n",
    "\n",
    "# Compute the Root Mean Squared Error\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "\n",
    "print(\"The Root Mean Squared Error for the random forest regression model with the best parameters:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angus/Documents/GitHub/MLFlow/OAI-lab1/myenv/lib/python3.9/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Dabl simple regressor' already exists. Creating a new version of this model...\n",
      "Created version '9' of model 'Dabl simple regressor'.\n"
     ]
    }
   ],
   "source": [
    "# Implement MLflow\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Log the RMSE metric\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Set a tag for tracking information\n",
    "    mlflow.set_tag(\"Training Info\", \"Dataset 2\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, simple_regressor.predict(X_train))\n",
    "    \n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=simple_regressor,\n",
    "        artifact_path=\"Dabl_simple_regressor\",\n",
    "        signature=signature,\n",
    "        input_example=X_train.head(),\n",
    "        registered_model_name=\"Dabl simple regressor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Root Mean Squared Error for the random forest regression model: 1625515.8711564096\n"
     ]
    }
   ],
   "source": [
    "# Create a base model\n",
    "rf_model = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Train the model using the best parameters\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Compute the Root Mean Squared Error\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, rf_pred))\n",
    "\n",
    "print(\"The Root Mean Squared Error for the random forest regression model:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angus/Documents/GitHub/MLFlow/OAI-lab1/myenv/lib/python3.9/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Random Forest Model' already exists. Creating a new version of this model...\n",
      "Created version '5' of model 'Random Forest Model'.\n"
     ]
    }
   ],
   "source": [
    "# Implement MLflow\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(rf_model.get_params())\n",
    "\n",
    "    # Log the RMSE metric\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Set a tag for tracking information\n",
    "    mlflow.set_tag(\"Training Info\", \"Dataset 2\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, rf_model.predict(X_train))\n",
    "\n",
    "    # Visualize feature importance\n",
    "    feature_importance = pd.DataFrame({'feature': X_train.columns, 'importance': rf_model.feature_importances_})\n",
    "    feature_importance = feature_importance.sort_values(by='importance', ascending=False)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "    plt.title('Feature Importance')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"feature_importance.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Log artifact (feature importance plot)\n",
    "    mlflow.log_artifact(\"feature_importance.png\")\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=rf_model,\n",
    "        artifact_path=\"Random_Forest_Model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train.head(),\n",
    "        registered_model_name=\"Random Forest Model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Light Gradient Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 123\n",
      "[LightGBM] [Info] Number of data points in the train set: 436, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 4706527.385321\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "The Root Mean Squared Error for the LGB model: 1509663.1888506506\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Train the model with the best parameters\n",
    "lgb_model = lgb.LGBMRegressor(random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lgb_pred = lgb_model.predict(X_test)\n",
    "\n",
    "# Compute the Root Mean Squared Error\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, lgb_pred))\n",
    "\n",
    "print(\"The Root Mean Squared Error for the LGB model:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angus/Documents/GitHub/MLFlow/OAI-lab1/myenv/lib/python3.9/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'LGB_Model' already exists. Creating a new version of this model...\n",
      "Created version '6' of model 'LGB_Model'.\n"
     ]
    }
   ],
   "source": [
    "# Implement MLflow\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(lgb_model.get_params())\n",
    "\n",
    "    # Log the RMSE metric\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Set a tag for tracking information\n",
    "    mlflow.set_tag(\"Training Info\", \"Dataset 2\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, lgb_model.predict(X_train))\n",
    "\n",
    "    # Visualize feature importance\n",
    "    feature_importance = pd.DataFrame({'feature': X_train.columns, 'importance': lgb_model.feature_importances_})\n",
    "    feature_importance = feature_importance.sort_values(by='importance', ascending=False)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "    plt.title('Feature Importance')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"feature_importance.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Log artifact (feature importance plot)\n",
    "    mlflow.log_artifact(\"feature_importance.png\")\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=lgb_model,\n",
    "        artifact_path=\"LGB_Model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train.head(),\n",
    "        registered_model_name=\"LGB_Model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Root Mean Squared Error for the Ridge Regression model: 1514047.544478292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Initialize the Ridge Regression model\n",
    "ridge = Ridge(random_state=0)\n",
    "\n",
    "# Train the model using the best parameters\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "ridge_pred = ridge.predict(X_test)\n",
    "\n",
    "# Compute the Root Mean Squared Error\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, ridge_pred))\n",
    "\n",
    "print(\"The Root Mean Squared Error for the Ridge Regression model:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angus/Documents/GitHub/MLFlow/OAI-lab1/myenv/lib/python3.9/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Ridge_Regression_Model' already exists. Creating a new version of this model...\n",
      "Created version '5' of model 'Ridge_Regression_Model'.\n"
     ]
    }
   ],
   "source": [
    "# Implement MLflow\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(ridge.get_params())\n",
    "\n",
    "    # Log the RMSE metric\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Set a tag for tracking information\n",
    "    mlflow.set_tag(\"Training Info\", \"Dataset 2\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, ridge.predict(X_train))\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=ridge,\n",
    "        artifact_path=\"Ridge_Regression_Model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train.head(),\n",
    "        registered_model_name=\"Ridge_Regression_Model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-08 12:10:53 -0500] [26124] [INFO] Starting gunicorn 21.2.0\n",
      "[2024-02-08 12:10:53 -0500] [26124] [INFO] Listening at: http://127.0.0.1:5000 (26124)\n",
      "[2024-02-08 12:10:53 -0500] [26124] [INFO] Using worker: sync\n",
      "[2024-02-08 12:10:53 -0500] [26125] [INFO] Booting worker with pid: 26125\n",
      "[2024-02-08 12:10:53 -0500] [26126] [INFO] Booting worker with pid: 26126\n",
      "[2024-02-08 12:10:53 -0500] [26127] [INFO] Booting worker with pid: 26127\n",
      "[2024-02-08 12:10:53 -0500] [26128] [INFO] Booting worker with pid: 26128\n",
      "^C\n",
      "[2024-02-08 12:11:45 -0500] [26124] [INFO] Handling signal: int\n",
      "[2024-02-08 12:11:45 -0500] [26125] [INFO] Worker exiting (pid: 26125)\n",
      "[2024-02-08 12:11:45 -0500] [26126] [INFO] Worker exiting (pid: 26126)\n",
      "[2024-02-08 12:11:45 -0500] [26127] [INFO] Worker exiting (pid: 26127)\n",
      "[2024-02-08 12:11:45 -0500] [26128] [INFO] Worker exiting (pid: 26128)\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
